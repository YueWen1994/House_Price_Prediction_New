---
title: "zillow project --- tree based model"
author: "YueWen"
date: "August 18, 2017"
output: html_document
---
## Missing data imputation

In HW3, we have finsihed missing data imputation, so all the data is complete, and here we import the imputated data directly from preveious work.
```{r,warning=FALSE,message=FALSE}
setwd("D:/data_camp/zillow_project")
#this csv is derived by imputation_part2.R 
train <- read.csv('train_imputed2.csv', stringsAsFactors = F)
```
## Feture engineering
However, regard to  the feature engineering part. We made one changes to tailor the need for tree-based methods.

1) Change build year to  numerical type,  and impute the missing value by randomly sampling. The practive can be validated by two reasons: the first is that built-year is not strong related to other features, so we might don't want to use mice to impute it. The second is that for tree based method, built-year will have more power as numerical value.

2) For interacttion terms, we create it in this part because I  don't  know how t

3) For other feature engineering part, we use the same collpase category method and new features as in HW3. However, we will delete all the ananlysis part for generating new  features,  such as  t-test, correlaton analysis.

### Handle variable type

```{r,warning=FALSE,message=FALSE}
train <- train[,!names(train) %in%c("X.1","X","trans_year")]
variable_numeric = c("area_firstfloor_finished",
                     "area_base", "area_base_living",
                     "area_garage", 
                     "area_live_finished",
                     "area_liveperi_finished",
                     "area_lot",
                     "area_patio",
                     "area_pool",
                     "area_shed",
                     "area_total_calc",
                     "area_total_finished",
                     "area_unknown",
                     "tax_building",
                     "tax_land",
                     "tax_property",
                     "tax_total",
                     "latitude",
                     "longitude")
# discrete
variable_discrete = c("num_75_bath",
                      "num_bath",
                      "num_bathroom",
                      "num_bathroom_calc",
                      "num_bedroom",
                      "num_fireplace",
                      "num_garage",
                      "num_pool",
                      "num_room",
                      "num_story",
                      "num_unit")
variable_binary = c("flag_fireplace",
                    "flag_tub",
                    "flag_spa",
                    "flag_pool_spa",
                    "flag_pool_tub",
                    "tax_delinquency")

# categorical variable
variable_nominal = c("aircon",
                     "architectural_style",
                     "county",
                     "deck",
                     "framing",
                     "heating",
                     "id_parcel",
                     "material",
                     "region_city",
                     "region_county",
                     "region_neighbor",
                     "region_zip",
                     "story",
                     "zoning_landuse",
                     "zoning_landuse_county")
variable_ordinal = c("quality")

# date
variable_date = c("tax_year",
                  "build_year",
                  "tax_delinquency_year",
                  "trans_year",
                  "trans_month",
                  "trans_day",
                  "trans_date",
                  "trans_weekday")

# others
variable_unstruct = c("zoning_property")

# don't understand
variable_unknown = c('censustractandblock',
                     'rawcensustractandblock')

# Conversion
# - convert some binary to 0, 1
# - convert to date to int
# - convert to numeric to double
# - convert to discrete to int
# - convert to categorical to character
train[train$flag_fireplace == "", "flag_fireplace"] = 0
train[train$flag_fireplace == "true", "flag_fireplace"] = 1
train[train$flag_tub == "", "flag_tub"] = 0
train[train$flag_tub == "true", "flag_tub"] = 1
train[train$tax_delinquency == "", "tax_delinquency"] = 0
train[train$tax_delinquency == "Y", "tax_delinquency"] = 1
# convert to date to int
train[,variable_date[variable_date %in% names(train)]] = 
  sapply(train[,variable_date[variable_date %in% names(train)]], as.character)
# convert to numeric to double
train[,variable_numeric[variable_numeric %in% names(train)]] = 
  sapply(train[,variable_numeric[variable_numeric %in% names(train)]], as.numeric)
# convert to discrete to int
combine_int_col = c(variable_discrete, variable_binary)
train[,combine_int_col[combine_int_col %in% names(train)]] = 
  sapply(train[,combine_int_col[combine_int_col %in% names(train)]], as.integer)
# convert to categorical to character
combine_char_col =  c(variable_nominal, variable_ordinal)
train[,combine_char_col[combine_char_col %in% names(train)]] = 
  sapply(train[,combine_char_col[combine_char_col %in% names(train)]], as.character)
```

### date related feature
```{r,echo = FALSE, warning=FALSE,message=FALSE}
#here we simply sample build_year
set.seed(500)
train$build_year[is.na(train$build_year)] <- sample(train$build_year[!is.na(train$build_year)],
                                                     
# in tree's model, we use build year as numerical variable.
#and randomly sample the missing value 
date.feature <- c("build_year")
```

### roomcnt realted feature
```{r,echo = FALSE, warning=FALSE,message=FALSE}
#roomcnt
###
#t.test shows it does matter to have right room number, so  crate a new level
with(train,t.test(abs(logerror)~ num_room >= num_bedroom + num_bathroom))
train$right_room <- with(train,ifelse(num_room >= num_bedroom + num_bathroom,1,0))
train$bed_to_bath <- with(train,ifelse(num_bathroom == 0, 0,num_bedroom/num_bathroom))
train$are_per_room<- with(train,ifelse(num_room == 0, 0, area_total_calc/num_room))
train$zero_room <- with(train, ifelse(num_room  ==0 ,1,0))

room.area.feature <- c("num_room","num_bedroom","num_bathroom","right_room","bed_to_bath",
                       "are_per_room","zero_room","area_total_calc")

```
##################################
#equipment
####################
table(train$aircon)
by(train,train$aircon,function(x){mean(x$logerror)})
#rebuild level based on mean  log_error
train$new.aircon = with(train,ifelse(aircon=="missing",aircon,
                                     ifelse(aircon=="5"|aircon=="13","5/13",
                                            ifelse(aircon=="11","11","1/3/9"))))

table(train$heating)
by(train,train$heating,function(x){mean(x$logerror)})
train$new.heating = with(train,ifelse(heating == "missing",heating,
                                      ifelse(heating %in% c("10","11","12","13","14","20","24"),"neg",
                                             ifelse(heating %in% c("6","7"),"6/7","2/1/18"))))
train$missing.heating <- with(train,ifelse(heating == "missing",1,0))
train$missing.aircon <- with(train,ifelse(aircon == "missing",1,0))
facility.feature <- c("flag_tub","flag_fireplace","missing.aircon","new.heating")
#,"new.aircon","new.heating")
#####################################
##tax####
#####################################
with(train,cor(tax_delinquency,logerror))
train$tax.perc <- train$tax_property/ train$tax_total
with(train,cor(tax.perc,logerror)) 
train$right.tax <-ifelse(train$tax.perc < 0.1,1,0)
train$build.to.total <- train$tax_building/train$tax_total
with(train,cor(build.to.total,logerror)) 
train$tax.per.area <-  train$tax_property/train$area_total_calc
tax.feature <- c("tax_delinquency","tax_total","tax_property","tax_land","right.tax","tax.per.area","build.to.total","tax.perc")
########################################
##quality###
########################################
quality.error <- by(train,train$quality, function(x){mean(x$logerror)})
table(train$quality) 
train$new.quality <- with(train,ifelse(quality=="missing",quality,
                                       ifelse(quality %in% c("12","7","11"),"12-7-11",
                                              ifelse(quality %in% c("4","1"), "4-1","6-8-10")
                                       )
                                       
))

quality.feature <- c("new.quality")
#########################################
###geo_info###
#########################################
zip.num <- by(train, train$region_zip, function(x) nrow(x))
train$zip.num <- zip.num[train$region_zip]
zip.area  <- by(train, train$region_zip, function(x) 
{abs((max(x$longitude) - min(x$longitude))*(max(x$latitude) - min(x$latitude)))})
train$zip.area <- zip.area[train$region_zip]

zip.density <- ifelse(zip.area  == 0 , 0 ,zip.num/zip.area)
zip.density.accuracy <- ifelse(zip.num>50,1,0)
zip.density.revised  <- zip.density*zip.density.accuracy
train$zip.density.revised <- zip.density.revised[train$region_zip]

plot(density(zip.density))
plot(zip.density)
train$zip.density <- zip.density[train$region_zip]
with(train,cor(zip.density,logerror))
with(train,cor(zip.density,abs(logerror)))
train$zip.density <- zip.density[train$region_zip]

##
city.zip <- by(train,train$region_city, function(x){length(unique(x$region_zip))})
train$zip.per.city <- city.zip[train$region_city]
with(train,cor(zip.per.city ,logerror))
city.area <- by(train, train$region_city, function(x){abs((max(x$longitude) - min(x$longitude))*(max(x$latitude) - min(x$latitude)))})
city.num  <- by(train, train$region_city, function(x) nrow(x))
city.density <- city.area/city.num
train$city.density <- city.density[train$region_city]
with(train,cor(city.density ,abs(logerror)))
train$county6111 <- with(train, ifelse(county == "6111",1,0))
####for now.
geo.feature<- c("county6111","zip.density.revised")
####
selected.feature <- c("logerror",geo.feature,quality.feature,tax.feature,facility.feature,room.area.feature,date.feature)
tree.df <- train[,selected.feature]

# train/test split
set.seed(500)
train.ind <- sample(nrow(tree.df),0.7*nrow(tree.df))
train.set <- tree.df[train.ind,]
test.set <- tree.df[-train.ind,]

##tree method
x_formula <- paste(names(train.set[,-1]),collapse = "+")
formula  <- as.formula(paste("logerror~",x_formula))
#########################################
#1#. simple tree method##################
#########################################
library(rpart)
# step1 
tree0 <- rpart(formula, data = train.set, control = rpart.control(cp= 0.0001))
printcp(tree0)
plotcp(tree0)
#step  2: pick up the tree size that minimizes the c-v error
#we can see cross  validation error increases first and then decreases
# therefore, let us choose the best control paramter 
bestcp <- tree0$cptable[which.min(tree0$cptable[,"xerror"]),"CP"]

#step 3: prune the tree with best cp
tree0.pruned <- prune(tree0,cp = bestcp)

#calculate mse
test.pred <- predict(tree0.pruned,newdata = test.set)
tree0.mse <- sum((test.pred - test.set$logerror)^2)/length(test.pred)


plot(tree0.pruned)
plot(tree0.pruned, uniform = T)
text(tree0.pruned, cex = 0.8, use.n = TRUE, xpd = TRUE)
library(rpart.plot)
prp(tree0.pruned, faclen = 0, cex = 0.8)
###########################
#2#Random Forest
##############
library(randomForest)
#we can use the same formula we used before
#just a reminder of what we features we selected
print(formula)
factor.feature <- c("new.quality","new.heating")
train.set$new.heating <- as.factor(train.set$new.heating)
train.set$new.quality <- as.factor(train.set$new.quality)
test.set$new.heating <- as.factor(test.set$new.heating)
test.set$new.quality <- as.factor(test.set$new.quality)
#we use the default ntree = 50 for now to see the initial result
# it takes too long to run, we save  it as Rdata and import it directly 
#rf <- randomForest(formula,data = train.set,importance = TRUE, ntree = 50)
#save("rf",file="rf.RData")
load("rf.RData")
# take  a look at the first tree
getTree(rf, k = 1, labelVar = TRUE)

varImpPlot(rf,type = 1)
# Let us interpret the result of  random forest, we only use
# the  increase mse  plot.
#as we can see, tax.percentage is still an important feature,
# as showned in the pruned tree. 
#However, build year is  also imporatnt feature in random forest model
#This is  different from linear model.
#flag_tub and flag_fireplace are still not important features, which  is the 
#same as in linear model.

importanceOrder= order(rf$importance[, "%IncMSE"], decreasing = T)
names = rownames(rf$importance)[importanceOrder]

partialPlot(rf, train.set, eval('tax.perc'), xlab='tax.perc')
partialPlot(rf, train.set, eval('build_year'), xlab='build_year')
# the resulta are very hard to interpret, but bascally we can see the logerror improves after1985

plot(rf) # see oob error

# we can see the  out of bag error decreases as the number  of trees increase, and 30 seems to
# be a knee point for this curve, which make it a reasonable numbe for the number of tree

#the next step: let us calculate  MSE
rf.pred <- predict(rf,test.set)
rf.mse <- mean((rf.pred- test.set$logerror)^2)
# rf.mse model  is worse then the base tree model, however, this is just an attempt,
# we will refine our model later.

######################
#3.cgboosting############
########################
library(xgboost)
xgboost.train.label <- train.set$logerror
xgboost.test.label <- test.set$logerror

xgboost.feature.matrix <- model.matrix(~.,data = train.set[,-1])
set.seed(1)

gbt <- xgboost(data = xgboost.feature.matrix,
               label = xgboost.train.label,
               max_depth = 10,
               nround = 200,
               objective = "reg:linear",
               verbose = 1)
# Then let us take a look at importance
importance <- xgb.importance(feature_names = colnames(xgboost.feature.matrix), model = gbt)
importance
library(Ckmeans.1d.dp)
xgb.plot.importance(importance)
# We can see, here, we still use gain to measure the importance feature.
# Here, tax_toal, zip.density.rivised, tax.perc  is  important features,
# And as we recall in the random forest model, they are important features there
# as well, just the order of importance might change a little bit here

# then let us  choose parameters to find the optimal tree
par <- list( max_depth = 8,
             objective = "reg:linear",
             nthread = 3,
             verbose = 2)
gbt.cv <- xgb.cv(params = par,
                 data = xgboost.feature.matrix, label = xgboost.train.label,
                 nfold = 5, nrounds = 100)

plot(gbt.cv$evaluation_log$train_rmse_mean, type = 'l')
lines(gbt.cv$evaluation_log$test_rmse_mean, col = 'red')
# we can  see when the number of  tree is bigger than 10, the performance of the model
# does  not improve anymore.  
# Again, we can see the bias-variance trade off here.
nround = which(gbt.cv$evaluation_log$test_rmse_mean == min(gbt.cv$evaluation_log$test_rmse_mean)) # 11
# then let us fit the model again using the best parameter when n =12
best.tree.gbt <- xgboost(data = xgboost.feature.matrix, 
               label = xgboost.train.label,
               nround = nround,
               params = par)

# to compare with other methods, let us calculate the mse
best.tree.gbt.pred <- predict(best.tree.gbt, model.matrix(~.,data = test.set[,-1]))
best.tree.gbt.mse  <- mean((best.tree.gbt.pred - test.set$logerror)^2)
#the error is slightly smaller than random forest, bigger than simple tree method
# which is very disappointig.
#However, it is not sufficient only to choose the number'
# of trees, let us use grid search to search the optimal parameters.

#################
###grid searching for boosting
#################
# here, we refer the code from Mr. Lin'c code  from code lab. We noticed
# that here rmse is used instead of mse
# given the fact that these two metrics are equivalent by nature,  we will use
# it to tune our model as well as modify features to improve the performance of
# the  model later.

all_param = NULL
all_test_rmse = NULL
all_train_rmse = NULL

######  Takes too long to run, take it out! only save the best paramter
# for (iter in 1:20) {
#   print(paste("-------", iter,"-------"))
#   
#   param <- list(objective = "reg:linear",
#                 max_depth = sample(5:12, 1),
#                 subsample = runif(1, .6, .9),
#                 colsample_bytree = runif(1, .5, .8)
#                 #   eta = runif(1, .01, .3)
#                 #  gamma = runif(1, 0.0, 0.2),
#                 #  min_child_weight = sample(1:40, 1),
#                 #  max_delta_step = sample(1:10, 1)
#   )
#   cv.nround = 100
#   cv.nfold = 5
#   seed.number = sample.int(10000, 1)[[1]]
#   set.seed(seed.number)
#   mdcv <- xgb.cv(data=xgboost.feature.matrix,
#                  label = xgboost.train.label,
#                  params = param, 
#                  nfold=cv.nfold,
#                  nrounds=cv.nround,
#                  #metrics = "mae",
#                  early_stopping_rounds = 10, 
#                  maximize=FALSE)
#   min_train_rmse = min(mdcv$evaluation_log$train_rmse_mean)
#   min_test_rmse = min(mdcv$evaluation_log$test_rmse_mean)
#   
#   all_param <- rbind(all_param, unlist(param)[-1])
#   all_train_rmse <- c(all_train_rmse, min_train_rmse)
#   all_test_rmse <- c(all_test_rmse, min_test_rmse)
# }
# 
# all_param <- as.data.frame(all_param)
# save("all_param", file = "all_param.RData")
load("all_param.RData")
best_param <- all_param[which(all_test_rmse == min(all_test_rmse)), ]
grid.search.gbt <- xgboost(data =  xgboost.feature.matrix, 
               label = xgboost.train.label, 
               params = best_param,
               nrounds=100,
               early_stopping_rounds = 10,
               maximize = FALSE)

# prediction
grid.search.pred <- predict(grid.search.gbt, model.matrix(~.,data = test.set[,-1]))
mean((grid.search.pred - test.set$logerror)^2)

mean((mean(test.set$logerror)- test.set$logerror)^2)
# as we can see, our model is worse than random guess, then  let us improve it!
# we keep the same parameter as before to save time given selecting parameters does
#  not really help us in previous situation.

# improvement1 -> reduce useless features 
#let us take a look at the importance, and then drop the redundant feature to
#see  how the results are improved.
importance <- xgb.importance(feature_names = colnames(train.data), model = gbt)
xgb.plot.importance(importance, top_n = 10)
